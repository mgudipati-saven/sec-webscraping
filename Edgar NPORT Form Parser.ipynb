{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first make a function that will make the process of building a url easy.\n",
    "def make_url(base_url , comp):\n",
    "    url = base_url\n",
    "    \n",
    "    # add each component to the base url\n",
    "    for r in comp:\n",
    "        url = '{}/{}'.format(url, r)\n",
    "        \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to parse an NPORT-P form type filing\n",
    "def parse_nport_form(filing_url):\n",
    "    doc_dict = {}\n",
    "    \n",
    "    # request the url, and then parse the response.\n",
    "    response = requests.get(filing_url)\n",
    "    soup = BeautifulSoup(response.content, 'xml')\n",
    "\n",
    "    doc_dict['asof_date'] = soup.find('repPdDate').text.strip() if soup.find('repPdDate') else ''\n",
    "    doc_dict['cik_number'] = int(soup.find('cik').text) if soup.find('cik') else ''\n",
    "    doc_dict['series_name'] = soup.find('seriesName').text.strip() if soup.find('seriesName') else ''\n",
    "    doc_dict['total_assets'] = float(soup.find('totAssets').text) if soup.find('totAssets') else '0.0'\n",
    "    doc_dict['net_assets'] = float(soup.find('netAssets').text) if soup.find('netAssets') else '0.0'\n",
    "\n",
    "    seriesId = soup.find('seriesId').text.strip() if soup.find('seriesId') else ''\n",
    "    doc_dict['series_number'] = int(seriesId[1:]) if (seriesId.startswith('S')) else ''\n",
    "\n",
    "    tickers = soup.find_all('CLASS-CONTRACT-TICKER-SYMBOL')\n",
    "    doc_dict['series_tickers'] = [ticker.text.strip() for ticker in tickers]\n",
    "    \n",
    "    invstOrSecs = soup.find_all('invstOrSec')\n",
    "    doc_dict['holdings'] = []\n",
    "    \n",
    "    for invstOrSec in invstOrSecs:\n",
    "        holding = {}\n",
    "        holding['holding_name'] = invstOrSec.find('title').text.strip() if invstOrSec.find('title') else 'N/A'\n",
    "        holding['holding_share'] = float(invstOrSec.find('balance').text) if invstOrSec.find('balance') else 0.0\n",
    "        holding['holding_value'] = float(invstOrSec.find('valUSD').text) if invstOrSec.find('valUSD') else 0.0\n",
    "        holding['holding_type'] = invstOrSec.find('assetCat').text.strip() if invstOrSec.find('assetCat') else 'OTHER'\n",
    "        doc_dict['holdings'].append(holding)\n",
    "    \n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the parameters to build the master index file url\n",
    "base_url = r\"https://www.sec.gov/Archives/edgar/daily-index\"\n",
    "year = '2020'\n",
    "qtr = 'QTR3'\n",
    "date = '20200717'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the master index file\n",
    "file_url = make_url(base_url, [year, qtr, 'master.{}.idx'.format(date)])\n",
    "content = requests.get(file_url).content\n",
    "\n",
    "# we can always write the content to a file, so we don't need to request it again.\n",
    "with open('master_20200717.csv', 'wb') as f:\n",
    "     f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the master index file into a pandas dataframe\n",
    "df = pd.read_csv('master_20200717.csv', delimiter='|', skiprows=5, parse_dates=['Date Filed'])\n",
    "df_nport = df[df['Form Type'] == 'NPORT-P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to hold the parsed NPORT form data\n",
    "base_url = r\"https://www.sec.gov/Archives\"\n",
    "\n",
    "nports_dict = {}\n",
    "for index, row in df_nport.iterrows():\n",
    "    filing_url = make_url(base_url, [row['File Name']])\n",
    "    nport_data = parse_nport_form(filing_url)\n",
    "\n",
    "    # add the filing date\n",
    "    nport_data['filing_date'] = row['Date Filed'].strftime('%Y-%m-%d')\n",
    "\n",
    "    # create a key to store the parsed data dictionary\n",
    "    key = 'NPORT-P_{}_{}_{}'.format(row['Company Name'], nport_data['series_name'], nport_data['filing_date'])\n",
    "    nports_dict[key] = nport_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each NPORT form data into it's own file\n",
    "for key, val in nports_dict.items():\n",
    "    \n",
    "    # file name based on the key\n",
    "    file_name = '{}.csv'.format(key)\n",
    "    \n",
    "    with open(file_name, 'w') as f:\n",
    "        # write the first header row\n",
    "        # As of Date\tFiling Date\tCIK Number\tSeries Number\tSeries name\tTotal Stocks Value\tTotal Assets\tTotal net Assets\tSeries Ticker1\n",
    "        header_1 = ['As of Date',\n",
    "                    'Filing Date', \n",
    "                    'CIK Number', \n",
    "                    'Series Number', \n",
    "                    'Series name', \n",
    "                    'Total Stocks Value', \n",
    "                    'Total Assets', \n",
    "                    'Total net Assets'\n",
    "                   ] + ['Series Ticker{}'.format(i+1) for i in range(len(val['series_tickers']))]\n",
    "        f.write('|'.join(header_1))\n",
    "        f.write('\\n')\n",
    "        \n",
    "        # write the first value row for the header\n",
    "        # 2020-04-30\t2020-06-26\t877232\t7715\tGreen Century Equity Fund\t317251629\t318112687\t318798341\tGCEQX\n",
    "        row_1 = [val['asof_date'],\n",
    "                 val['filing_date'],\n",
    "                 str(val['cik_number']),\n",
    "                 str(val['series_number']),\n",
    "                 val['series_name'],\n",
    "                 '',\n",
    "                 str(val['total_assets']),\n",
    "                 str(val['net_assets'])\n",
    "                ] + [ticker for ticker in val['series_tickers']]\n",
    "        f.write('|'.join(row_1))\n",
    "        f.write('\\n')\n",
    "\n",
    "        # write the second header row\n",
    "        # Filing Classification\tHolding Type\tHolding Name\tHolding Share\tHolding Value\tHolding Face Amt\tHolding Number Of Contracts\tFuture Gain Or Loss\n",
    "        header_2 = 'Filing Classification|Holding Type|Holding Name|Holding Share|Holding Value|Holding Face Amt|Holding Number Of Contracts|Future Gain Or Loss'\n",
    "        f.write(header_2)\n",
    "        f.write('\\n')\n",
    "        \n",
    "        # write the holdings rows\n",
    "        for holding in val['holdings']:\n",
    "            row = '{}|{}|{}|{}|{}|0|0|0'.format(holding['holding_type'], \n",
    "                                       holding['holding_type'], \n",
    "                                       holding['holding_name'], \n",
    "                                       holding['holding_share'],\n",
    "                                       holding['holding_value']\n",
    "                                      )\n",
    "            f.write(row)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
